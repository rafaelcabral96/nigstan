# Spatial Matérn model

## Introduction

A famous class of processes is spatial statistics are stationary Gaussian processes with Matérn covariance function. Gaussian processes with this covariance function can be obtained as a solution of the SPDE equation (@lindgren2011explicit):

\begin{equation}\label{eq:SPDE}
(\kappa^2 - \Delta)^{\alpha/2} X(\mathbf{s}) = \sigma \mathcal{W}(\mathbf{s}), \ \ \mathbf{s} \in \mathbb{R}^d,
\end{equation}

where $\kappa^2$ is a spatial scale parameter, $\Delta=\sum_i \partial^2/\partial x_i^2$ is the Laplace operator, $\alpha$ is a smoothness parameter, and $\mathcal{W}(\mathbf{s})$ is a Gaussian white noise process.  The approximation to discrete space in @lindgren2011explicit uses the finite element method to the stochastic weak formulation of the previous SPDE. In 2D, it begins by expressing the process $X(\mathbf{s})$ as a sum of piecewise triangular basis functions:

$$
X(\mathbf{s}) = \sum_{i=1}^{n}w_i\psi_i(\mathbf{s})
$$
The spatial region of interest is partitioned into a set of  $n$ non-overlapping triangles creating a mesh, where each basis function $\psi_i(\mathbf{s})$ takes the value 1 inside a given triangle and 0 outside. The weights $w_i$ correspond to the process $X(\mathbf{s})$ at the nodes of the mesh. The distribution of the stochastic weights $\mathbf{w}=[w_1,\dotsc,w_n]^T$ was found by the Galerkin method and leads to the system $\mathbf{D}_\alpha\mathbf{w}=\mathbf{Z}$, where the Gaussian noise $Z_i$ has variance $\sigma^2h_i$ with $h_i=\int\psi_i(\mathbf{s})d\mathbf{s}$ being the area of the $i$th basis function. When $\alpha=2$, $\mathbf{D}_2=\kappa^{2} \mathbf{C}+\mathbf{G}$, where:
$$\mathbf{C}_{i j}=\int\psi_i(\mathbf{s})\psi_j(\mathbf{s})d\mathbf{s}, $$
$$\mathbf{G}_{i j}=\int \nabla\psi_i(\mathbf{s})\nabla\psi_j(\mathbf{s})d\mathbf{s}. $$
The mass-lumping technique is applied to approximate $\mathbf{C}$ with the diagonal matrix $\text{diag}(\mathbf{h})$, so that the precision matrices are sparse. Then, the precision matrix is $\sigma^{-2}\mathbf{D}_2 \text{diag}(\mathbf{h})^{-1}\mathbf{D}_2$
The random field $X(\mathbf{s})$ at locations $\mathbf{s}_1, \mathbf{s}_2, \dotsc$, that is $\mathbf{x}= [X(\mathbf{s}_1), X(\mathbf{s}_2), \dotsc]^T$, is then given by $\mathbf{x}= \mathbf{A}\mathbf{w}$, where $\mathbf{A}$ is the projector matrix with elements $A_{ij}=\psi_i(s_j)$. For even $\alpha>2$ we have $\mathbf{D}_{\alpha}= \mathbf{D}_2 \mathbf{C}^{-1} \mathbf{D}_{\alpha-2}$. 

 @bolin2014spatial extended the previous results to Type-G Matérn random fields by replacing the Gaussian noise process $\mathcal{W}(\mathbf{s})$ with normal-variance mixture distributions, from which the NIG distribution is a special case. From the more flexible noise distribution we get a Matérn random field that can better model short term variations and sharp peaks in the latent field, or "hotspots" and "coldspots", that is, marginal events that would be considered extreme in a Gaussian model. It was shown that the stochastic weights now follow the system $\mathbf{D}_\alpha\mathbf{w}=\mathbf{\Lambda}(\eta^\star,\mu^\star)$, where the matrix $\mathbf{D}_\alpha$ is the same as in the Gaussian case seen before and $\Lambda_i$ is NIG noise with variance $\sigma^2h_i$, and flexibility parameters $\eta^\star$ and $\mu^\star$. 


## Implementation

We are going to implement a latent NIG driven Matérn random field to temperature data in the northwest region of North America. This dataset was previously studied in @bolin2020multivariate. The main point of this section is to show how to extent a Gaussian model to non-Gaussianity using the function `modelNIG` and discuss the potential benefits of using a non-Gaussian latent field, rather than implementing a realistic climate model. The full Stan models are in  `..files\stan\GaussMaternSPDE.stan` and `..files\stan\NIGMaternSPDE.stan` and here we overview the main elements of the code.

We consider no covariates for the temperature data $\mathbf{y}$ and the projector matrix $A$ interpolates the random field that is being modeled at the mesh nodes on the measurement locations:

$$
\mathbf{y}|\mathbf{w} \sim N(\sigma\mathbf{A}\mathbf{w},\sigma_\epsilon) \\
 \mathbf{D}_2\mathbf{w} =  \mathbf{\Lambda}(\eta^\star,\mu^\star), \\ \ \text{where} \ \mathbf{D}_2 = \kappa^{2} \text{diag}(\mathbf{h})+\mathbf{G} 
$$

We leave out the priors for now, which will be discussed later.


### Libraries and data

```{r message=FALSE, warning=FALSE}
library(readr)                # Read csv files
library(INLA)                 # Compute discretization mesh and FEM matrices
library(leaflet)              # Interactive widgets
library(leaflet.extras)       # Fullscreen control for Leaflet widget
library(cmdstanr)             # CmdStan R interface
library(posterior)            # Process the output of cmdstanr sampling
library(bayesplot)            # Pair and trace plots
library(ggplot2)              # More plots
library(GIGrvg)               # Evaluate density of a GIG distribution
source("../files/utils.R")    # Several utility functions

options(mc.cores = parallel::detectCores())
```

The `weatherdata.csv` contains the temperature where the sample mean was subtracted from the data and the coordinates where the measurements were taken.

```{r message=FALSE, warning=FALSE}
weatherdata <- as.data.frame(read_csv("../files/data/weatherdata.csv", col_names = TRUE))
```

### Discretization mesh

Next, we create the triangle mesh to cover the studied region using the `inla.mesh.2d` function. We imputed `weatherdata[,c("lon","lat")]` which are the coordinates where the measurements were taken, `max.edge` is the maximum allowed edge for each triangle, cutoff is the minimum allowed distance between vertexes, and `max.n.strict` is the maximum number of nodes allowed. From the mesh object we obtain the matrix $\mathbf{G}$, the vector $\mathbf{h}$ (which contains the area of the basis functions), and the projector matrix $\mathbf{A}$.

```{r}
mesh <- inla.mesh.2d(loc = weatherdata[,c("lon","lat")], max.edge = c(1.5, 2.5), cutoff = 0.3, max.n.strict = 400)

Ny   <- length(weatherdata$temp)                  #Number of observations
N    <- mesh$n                                    #Number of nodes
fem  <- inla.mesh.fem(mesh, order=2)       
G    <- fem$g1
h    <- diag(fem$c0)

A <- inla.spde.make.A(mesh = mesh, loc = as.matrix(weatherdata[,c("lon","lat")]))
```

### Data plot

In the next Leaflet widget we plot the data and the discretization mesh. We hidden the Leaflet code here since it is quite long, but you can find it in the original Rmarkdown file in ??.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#inla.mesh2sp is a function in ../files/utils.R that convert an INLA mesh object to an sp mesh object that leaflet can process
mesh_map <- inla.mesh2sp(mesh)$triangles

#Leaflet expects data to be specified in latitude and longitude using the WGS84 coordinate projection, so we transform mesh_map to this projection as follows
proj4string(mesh_map) <- CRS("+proj=longlat +datum=WGS84")
mesh_map_proj <- spTransform(mesh_map, "+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")

paltemp  <- colorNumeric(palette = c("blue","white","red"), domain = weatherdata$temp)   #pallete for temperature data
palpress <- colorNumeric(palette = c("blue","white","red"), domain = weatherdata$press)  #pallete for pressure    data
leaflet(weatherdata) %>% 
  addProviderTiles(providers$Esri.WorldImagery) %>% 
  #Discretization mesh
  addPolygons(data=mesh_map_proj, weight = 1, fill = FALSE, color = "#0A0708") %>%
  #Temperature circle markers
  addCircleMarkers(lng = ~lon, lat = ~lat, color="black", 
                   stroke= TRUE, fill = TRUE, fillColor = ~paltemp(temp), 
                   radius = 5, fillOpacity = TRUE, weight = 1, group = "Temperature") %>%
  #Legend for temperature data
  addLegend_decreasing(pal = paltemp, values = ~temp, opacity = 0.8, title = "",
                       position = "bottomright", decreasing = TRUE, group = "Temperature") %>%
  #Pressure circle markers
  addCircleMarkers(lng = ~lon, lat = ~lat, color="black", 
                   stroke= TRUE, fill = TRUE, fillColor = ~palpress(press), 
                   radius = 5, fillOpacity = TRUE, weight = 1, group = "Pressure") %>%
  #Legend for pressure data
  addLegend_decreasing(pal = palpress, values = ~press, opacity = 0.8, title = "",
                       position = "bottomright", decreasing = TRUE, group = "Pressure") %>%
  #Layers 
  addLayersControl(overlayGroups = c("Temperature", "Pressure"),
                   options = layersControlOptions(collapsed = FALSE)) %>%
  hideGroup("Pressure") %>%
  addFullscreenControl()
```

### Priors

We use the default INLA prior for $\sigma_\epsilon$. The penalized complexity priors for the scale parameter $\sigma$ and spatial range parameter $\kappa$ were derived in @fuglstad2019constructing and their log likelihood can be defined in the model block as:

```{}
...
//prior layer---------------------------------
//prior for sigmae
sigmae ~ inv_gamma(1, 0.00005);
//prior for sigma and kappa
target += - log(kappa) - lambda1*kappa - lambda2*sigma/kappa;  
...
```

With the PC prior approach we get the distribution for the priors up to a scaling constant. The hyperparameters `lambda1` and `lambda2` are found by relating $\sigma$ and $\kappa$ with more interpretable parameters, namely the marginal standard deviation $\sigma_{marg}$ and the practical correlation range $\rho=\sqrt{8}/\kappa$ (the distance at which the correlation is approximately 0.1). Then `lambda1` and `lambda2` can be found by setting the probabilities $P(\rho<\rho_0)=\alpha$ and $P(\sigma_{marg}>\sigma_0)=\alpha$ as follows: 


```{r eval=FALSE}
# P(pract.range < 0.1) = 0.01
range_0        = 0.1
range_alpha    = 0.01

# P(marginal sd > 6) = 0.01
margsd_0        = 6
margsd_alpha    = 0.01

lambda1 = -log(range_alpha)*range_0/sqrt(8)
lambda2 = -log(margsd_alpha)/(margsd_0*sqrt(4*pi))
```

The priors for the parameter $\eta^\star$ and $\mu^\star$ are declared next:

```{}
...
//prior layer---------------------------------
//prior for etas
theta_etas = -4*log(alphaetas)*kappa^2;
target +=  log(theta_etas) - theta_etas*etas;
//prior for mus
target += - theta_mus*fabs(mus);
...
```

As motivated in @PCprior we use an exponential distribution for $\eta^\star$ with rate $4\log(\alpha_{\eta})\kappa^2$. The hyperparameter $\alpha_{\eta^\star}$ is the probability of having twice as much large marginal events compared with the Gaussian case: $P(Q(\eta,\kappa) > 2)= \alpha_{\eta^\star}$, where:
$$
Q(\eta,\kappa) =  \frac{P(|X_{\eta,\kappa}(t)|>3\sigma_{marg}(\kappa))}{P(|X_{\eta=0,\kappa}(t)|>3\sigma_{marg}(\kappa))} ,    
$$
The Laplace prior for $\mu^\star$ has rate parameter $\theta_{\mu^\star}= -\log(\alpha_{\mu^\star})2\sqrt{2}$, where $\alpha_{\mu^\star}$ is the probability that $|\gamma|$ (defined in \@ref(Tailcorrection)) is larger than 2 $P(|\gamma(\mu^\star)|>2)=\alpha_{\mu^\star}$. We will use $\alpha_{\eta^\star}=\alpha_{\mu^\star}=0.5$.
<!--
### Determinant

We precompute the determinant of $\mathbf{D}_2=\kappa^{2} \text{diag}(\mathbf{h})+\mathbf{G}$ in Log-Log scale, which is needed to evaluate the joint log-likelihood of $\mathbf{x}$ faster.

```{r message=FALSE, warning=FALSE}
a <- -3
b <- 3
inter_points <- 2500
kappa_log <- seq(a,b,,inter_points)
det_log <-c()
for(kappa in exp(kappa_log)){
  D       <- kappa^2*diag(h)+G
  det_log <- c(det_log, determinant(D,logarithm = TRUE)$modulus[1])
}
plot(kappa_log, det_log,type='l',  xlab = 'log(κ)', ylab = 'log(|D|)')
```
-->
We finally construct the list with all the required data.

```{r eval=FALSE}
dat1 <- list(N        = N,
             Ny       = Ny,
             y        = weatherdata$temp,
             h        = h,
             G        = as.matrix(G),
             A        = as.matrix(A),
             inter_points = inter_points,
             kappa_log    = kappa_log,
             det_log      = det_log,
             lambda1  = lambda1,
             lambda2  = lambda2,
             alphaeta = 0.5,
             thetamus  = 5)
```

### Stan fit with a Gaussian model

Note that the Gaussian log-likelihood for $\mathbf{w}$ where $\mathbf{D}\mathbf{w}=\mathbf{Z}$, and $Z_i \sim N(0,h_i)$ is given by:

$$\log\pi(\mathbf{x}) \propto\log |\mathbf{D}| - 0.5\sum_{i=1}^n [\mathbf{D}\mathbf{w}]_i^2/h_i.$$

We add the scale parameter $\sigma$ of the latent field $\mathbf{w}$ in the observation layer. The model block is shown next. 

```{}
model{
  //observation layer---------------------------
  y ~ normal(sigma*A*W, sigmae);

  //latent field layer--------------------------
  D  = add_diag(G, kappa^2*h);                                //D = kappa^2*C+ G
  target += -0.5*sum(square(D*W) ./ h);                       //Gaussian Log-likelihood
  target += interpolation(log(kappa), kappa_log, det_log);    //Log determinant of D

  //prior layer---------------------------------
  ...
}
```

Then we compile and fit the model.

```{r eval=FALSE}
model_stan_Gauss <- cmdstan_model('../files/stan/GaussMaternSPDE.stan')
fit_Gauss <- model_stan_Gauss$sample(data = dat1, 
                                     chains = 4, 
                                     iter_warmup   = 200, 
                                     iter_sampling = 1000)

fit_Gauss$save_object("../files/fits/fit_temp_Gauss.rds")
```

There were no warning messages. Let us examine the summary of the fit for a few parameters.

```{r}
fit_Gauss <- readRDS("../files/fits/fit_temp_Gauss.rds")
knitr::kable(head(fit_Gauss$summary(),7), "simple", row.names = NA, digits=2)
```

All parameters had large effective sample sizes (`ess_bulk` and `ess_ess_tail`) and acceptable $\hat{R}$ values. Next we have the pair and trace plots for $\sigma_\epsilon$, $\kappa$ and $\sigma$.

```{r}
mcmc_pairs(fit_Gauss$draws(c("sigmae", "sigma", "kappa")),
           diag_fun="dens", off_diag_fun="hex")

mcmc_trace(fit_Gauss$draws(c("sigmae", "sigma", "kappa")), 
           facet_args = list(ncol = 2, strip.position = "left"))
```

### Stan fit with a NIG driving noise

The model block for the NIG extension is given next. Since we already compute the log determinant by interpolation, we set the last argument of `modelNIG` to 0, so that the log determinant is not computed twice.

```{}
model{
  //observation layer---------------------------
  y ~ normal(sigma*A*W, sigmae);

  //latent field layer--------------------------
  D  = add_diag(G, kappa^2*h);                                //D = kappa^2*C+ G
  w  ~ modelNIG(D, etas, mus, h, 0)                           //NIG driven Log-likelihood
  target += interpolation(log(kappa), kappa_log, det_log);    //Log determinant of D
  
  //prior layer---------------------------------
  ...
}
```

```{r eval=FALSE, include=FALSE}
a <- -5
b <- 5
inter_points <- 1000
kappa_log <- seq(a,b,,inter_points)
det_log <-c()
for(kappa in exp(kappa_log)){
  D       <- kappa^2*diag(h)+G
  det_log <- c(det_log, determinant(D,logarithm = TRUE)$modulus[1])
}
plot(kappa_log, det_log,type='l',  xlab = 'log(κ)', ylab = 'log(|D|)')
```

```{r eval=FALSE, include=FALSE}
kappa=10

determinant(kappa^2*diag(h)+G,logarithm = TRUE)$modulus[1]

sum(log(h))+sum(log(kappa^2+eigen(diag(1/h)%*%G)$values))
```

We compile and fit the model next.

```{r eval=FALSE}
model_stan_NIG <- cmdstan_model('../files/stan/NIGMaternSPDE.stan')
fit_NIG <- model_stan_NIG$sample(data = dat1, 
                                 chains = 4, 
                                 iter_warmup =   200, 
                                 iter_sampling = 1000)

fit_NIG$save_object("../files/fits/fit_temp_NIG.rds")
```

There were no warning messages. The summary shows acceptable $\hat{R}$ values and sample sizes, although compared to the Gaussian fit the effective sample sizes of $\sigma_\epsilon$, $\sigma$, $\kappa$ are lower.

```{r}
fit_NIG   <- readRDS("../files/fits/fit_temp_NIG.rds")
knitr::kable(head(fit_NIG$summary(),9), "simple", row.names = NA, digits=2)
```

Next we plot the pair and trace plots of the posterior distributions of some parameters of the NIG model. The posterior means of $\sigma_\epsilon$ were smaller and of $\sigma$ were larger, indicating that more variability of the data could be explained by the NIG driven latent field. The posterior mean of $\kappa$ is higher indicating that the spatial correlation decays faster with distance. This is possibility caused by the peaks and short term variations in the data, that are now better modeled by the latent field. The posterior distribution of $\eta^\star$ indicates a clear departure from the Gaussian distribution, having mean 1.41. The 95\% posterior quantiles of  $\mu^\star$ include the 0, although most of the mass is in the positive domain.


```{r}
mcmc_pairs(fit_NIG$draws(c("sigmae", "sigma", "kappa","etas","mus")),
           diag_fun="dens", off_diag_fun="hex")

mcmc_trace(fit_NIG$draws(c("sigmae", "sigma", "kappa","etas","mus")), 
           facet_args = list(ncol = 2, strip.position = "left"))
```

Let us look at the posterior samples of latent field at some nodes. We can see that at node 1, the NIG model is more peaked than in the Gaussian case, and for node 94 it is more skewed to the left.

```{r message=FALSE, warning=FALSE}
bayesplot_grid(
  mcmc_hist(fit_Gauss$draws("W[1]")),
  mcmc_hist(fit_NIG$draws("W[1]")),
  titles = c("Posterior of w[1] - Gaussian model", "Posterior of w[1] - NIG model"),
  xlim = c(-2.5,2)
)

bayesplot_grid(
  mcmc_hist(fit_Gauss$draws("W[94]")),
  mcmc_hist(fit_NIG$draws("W[94]")),
  titles = c("Posterior of w[94] - Gaussian model", "Posterior of w[94] - NIG model"),
  xlim = c(-2,-0.5)
)
```

### Leave-one-out cross validation

We compare the Gaussian and NIG latent models using the leave-one-out cross-validation estimates of @vehtari2017practical, which gave preference for the NIG model.

```{r warning=FALSE}
fit_Gauss$loo()[[1]]
fit_NIG$loo()[[1]]
```

### Prediction

A common problem is spatial statistics is prediction, which in our context means finding the posterior distribution of the latent field $X(\mathbf{s})$ in locations where there are no measurement data. We will get posterior samples of $\mathbf{x}_{pred}$ which is the latent field $X(\mathbf{s})$ on a square grid spanning the studied region and containing $100^2$ nodes. First, we create the matrix `coop` containing the coordinates of the nodes in square grid and then `inla.mesh.spde.make.A()` creates the projector matrix $\mathbf{A_p}$ that links the original mesh nodes at which we modeled the latent field to the nodes of the new square grid. Finally, $\mathbf{x}_{pred} = \sigma  \mathbf{A_p}  \mathbf{w}$, where we will use the posterior samples from $\sigma$ and $\mathbf{w}$ obtained in Stan to generate posterior samples of $\mathbf{x}_{pred}$.

```{r message=FALSE, warning=FALSE}
#Square grid containing 100^2 nodes
n.grid <- 100
coop <- as.data.frame(expand.grid(seq(min(weatherdata$lon),max(weatherdata$lon),,n.grid), 
                                  seq(min(weatherdata$lat),max(weatherdata$lat),,n.grid)))
lenx <- (max(weatherdata$lon) - min(weatherdata$lon))/n.grid
leny <- (max(weatherdata$lat) - min(weatherdata$lat))/n.grid

#projector matrix for new grid
Ap   <-  inla.spde.make.A(mesh = mesh, loc = as.matrix(coop))

#Posterior samples from w
W_NIG   <- as.matrix(as_draws_df(fit_NIG$draws("W"))[,1:N])
#Posterior samples from sigma
sigma_NIG   <- as.matrix(as_draws_df(fit_NIG$draws("sigma")))[,1]
#Posterior samples of w_pred
W_NIG_pred   <- sigma_NIG * t(Ap %*% t(W_NIG)) 
```


We can visualize the posterior mean and standard deviation of $\mathbf{x}_{pred}$ in the following Leaflet widgets, as well as the probabilities that the latent field is larger than 4 and smaller than -4 in the prediction grid (for better visualization we only plotted the locations were this probability was larger than 10%). It is possible to choose between two different map providers and we choose same color scale in the Gaussian and NIG widgets. 

The posterior of the NIG latent field accurately captures the sharp peaks in the northeast region. There is a "hotpot" and "coldspot" close to one another and a Gaussian model over-smoothed the hotspot. The NIG model predictions have smaller standard deviation in regions with few or no observations. Also, the regions where the probability of having relative temperatures larger than 4 in absolute value are less scattered in the NIG model.

#### NIG prediction

```{r echo=FALSE, message=FALSE, warning=FALSE}
W_pred <- W_NIG_pred

# Plot data
colnames(coop) <- c("lng1","lat1")
coop$lng2 <- coop$lng1 + 1.01*lenx
coop$lat2 <- coop$lat1 + 1.01*leny
plot_data <- data.frame(lng1 = coop$lng1, lng2 = coop$lng2, lat1 = coop$lat1, lat2 = coop$lat2,
                        mean = colMeans(W_pred), 
                        sd  = apply(W_pred,2,sd),
                        p4  = apply(W_pred,2,function(x) mean(x> 4)),
                        pm4  = apply(W_pred,2,function(x) mean(x< -4)))

#Cutoff for probability plots
plot_data$include.p4 <- as.numeric(plot_data$p4>0.1)
plot_data$include.pm4 <- as.numeric(plot_data$pm4>0.1)

#Palletes
pal.mean  <- colorNumeric(palette = c("blue","white","red"), domain = c(-8.1,8.1))
pal.sd    <- colorNumeric(palette = c("YlOrRd"), domain = c(0.22,4.7))
pal.p4    <- colorNumeric(palette = c("white","red"), domain = plot_data$p4)
pal.pm4   <- colorNumeric(palette = c("white","blue"), domain = plot_data$pm4)

leaflet(plot_data) %>%
  
  addTiles(group = "OpenStreetMap") %>%
  addProviderTiles(providers$Esri.WorldImagery, group = "Sattelite") %>% 
  
  addCircleMarkers(data = weatherdata, lng = ~lon, lat = ~lat, color="black", 
                   stroke= TRUE, fill = TRUE, fillColor = ~paltemp(temp), 
                   radius = 5, fillOpacity = TRUE, weight = 1) %>%
  
  addRectangles(lng1 = ~lng1, lng2 = ~lng2, lat1 = ~lat1, lat2 = ~lat2, 
                fillColor = ~pal.mean(mean), fillOpacity = 0.8, stroke = FALSE, group = "Mean") %>%
  addLegend_decreasing(pal = pal.mean, values = ~mean, opacity = 0.8, title = "",
                       position = "bottomright", decreasing = TRUE, group = "Mean") %>%
  
  addRectangles(lng1 = ~lng1, lng2 = ~lng2, lat1 = ~lat1, lat2 = ~lat2, 
                fillColor = ~pal.sd(sd), fillOpacity = 0.8, stroke = FALSE, group = "Standard Deviation") %>%
  addLegend_decreasing(pal = pal.sd, values = ~sd, opacity = 0.8, title = "",
                       position = "bottomright", decreasing = TRUE, group = "Standard Deviation") %>%
  
  addRectangles(lng1 = ~lng1, lng2 = ~lng2, lat1 = ~lat1, lat2 = ~lat2, 
                fillColor = ~pal.p4(p4), fillOpacity = ~include.p4*0.8, stroke = FALSE, group = "Prob > 4") %>%
  addLegend_decreasing(pal = pal.p4, values = ~p4, opacity = 0.8, title = "",
                       position = "bottomright", decreasing = TRUE, group = "Prob > 4") %>%
  
  addRectangles(lng1 = ~lng1, lng2 = ~lng2, lat1 = ~lat1, lat2 = ~lat2, 
                fillColor = ~pal.pm4(pm4), fillOpacity = ~include.pm4*0.8, stroke = FALSE, group = "Prob < -4") %>%
  addLegend_decreasing(pal = pal.pm4, values = ~pm4, opacity = 0.8, title = "",
                       position = "bottomright", decreasing = TRUE, group = "Prob < -4") %>%

  addLayersControl(baseGroups = c("OpenStreetMap", "Sattelite"),
                   overlayGroups = c("Mean", "Standard Deviation", "Prob > 4", "Prob < -4"),
                   options = layersControlOptions(collapsed = FALSE)) %>%
  hideGroup(c("Standard Deviation", "Prob > 4", "Prob < -4")) %>%
  addFullscreenControl()
```

#### Gaussian prediction

```{r echo=FALSE, message=FALSE, warning=FALSE}
#Posterior samples from w
W_Gauss      <- as.matrix(as_draws_df(fit_Gauss$draws("W"))[,1:N])
#Posterior samples from sigma
sigma_Gauss  <- as.matrix(as_draws_df(fit_Gauss$draws("sigma")))[,1]
#Posterior samples of w_pred
W_Gauss_pred <- sigma_Gauss * t(Ap %*% t(W_Gauss)) 

W_pred <- W_Gauss_pred

# Plot data
colnames(coop) <- c("lng1","lat1")
coop$lng2 <- coop$lng1 + 1.01*lenx
coop$lat2 <- coop$lat1 + 1.01*leny
plot_data <- data.frame(lng1 = coop$lng1, lng2 = coop$lng2, lat1 = coop$lat1, lat2 = coop$lat2,
                        mean = colMeans(W_pred), 
                        sd  = apply(W_pred,2,sd),
                        p4  = apply(W_pred,2,function(x) mean(x> 4)),
                        pm4  = apply(W_pred,2,function(x) mean(x< -4)))

#Cutoff for probability plots
plot_data$include.p4 <- as.numeric(plot_data$p4>0.1)
plot_data$include.pm4 <- as.numeric(plot_data$pm4>0.1)

#Palletes
pal.mean  <- colorNumeric(palette = c("blue","white","red"), domain = c(-8.1,8.1))
pal.sd    <- colorNumeric(palette = c("YlOrRd"), domain = c(0.22,4.7))
pal.p4    <- colorNumeric(palette = c("white","red"), domain = plot_data$p4)
pal.pm4   <- colorNumeric(palette = c("white","blue"), domain = plot_data$pm4)

leaflet(plot_data) %>%
  
  addTiles(group = "OpenStreetMap") %>%
  addProviderTiles(providers$Esri.WorldImagery, group = "Sattelite") %>% 
  
  addCircleMarkers(data = weatherdata, lng = ~lon, lat = ~lat, color="black", 
                   stroke= TRUE, fill = TRUE, fillColor = ~paltemp(temp), 
                   radius = 5, fillOpacity = TRUE, weight = 1) %>%
  
  addRectangles(lng1 = ~lng1, lng2 = ~lng2, lat1 = ~lat1, lat2 = ~lat2, 
                fillColor = ~pal.mean(mean), fillOpacity = 0.8, stroke = FALSE, group = "Mean") %>%
  addLegend_decreasing(pal = pal.mean, values = ~mean, opacity = 0.8, title = "",
                       position = "bottomright", decreasing = TRUE, group = "Mean") %>%
  
  addRectangles(lng1 = ~lng1, lng2 = ~lng2, lat1 = ~lat1, lat2 = ~lat2, 
                fillColor = ~pal.sd(sd), fillOpacity = 0.8, stroke = FALSE, group = "Standard Deviation") %>%
  addLegend_decreasing(pal = pal.sd, values = ~sd, opacity = 0.8, title = "",
                       position = "bottomright", decreasing = TRUE, group = "Standard Deviation") %>%
  
  addRectangles(lng1 = ~lng1, lng2 = ~lng2, lat1 = ~lat1, lat2 = ~lat2, 
                fillColor = ~pal.p4(p4), fillOpacity = ~include.p4*0.8, stroke = FALSE, group = "Prob > 4") %>%
  addLegend_decreasing(pal = pal.p4, values = ~p4, opacity = 0.8, title = "",
                       position = "bottomright", decreasing = TRUE, group = "Prob > 4") %>%
  
  addRectangles(lng1 = ~lng1, lng2 = ~lng2, lat1 = ~lat1, lat2 = ~lat2, 
                fillColor = ~pal.pm4(pm4), fillOpacity = ~include.pm4*0.8, stroke = FALSE, group = "Prob < -4") %>%
  addLegend_decreasing(pal = pal.pm4, values = ~pm4, opacity = 0.8, title = "",
                       position = "bottomright", decreasing = TRUE, group = "Prob < -4") %>%

  addLayersControl(baseGroups = c("OpenStreetMap", "Sattelite"),
                   overlayGroups = c("Mean", "Standard Deviation", "Prob > 4", "Prob < -4"),
                   options = layersControlOptions(collapsed = FALSE)) %>%
  hideGroup(c("Standard Deviation", "Prob > 4", "Prob < -4"))%>%
  addFullscreenControl()
```


### Posterior distribution of $\mathbf{V}\oslash\mathbf{h}$

In the Gaussian case the vector $\mathbf{V}\oslash\ \mathbf{h}$ is equal to $\mathbf{1}$, and so the plot of the posterior mean of $\mathbf{V}\oslash\ \mathbf{h}$  can be used as a diagnostic plot to access where departures from Gaussianity occur and if a non-Gaussian model is needed at all. We prefer looking at this diagnostic plot, rather than the posterior distribution of $\eta^\star$, since the visual semblance of the latent field for the same value of $\eta^\star$ depends on the domain area and the discretization mesh and so it cannot be used to compare different datasets. The function `Vposterior` in `..files\utils.R` can generate posterior samples of $\mathbf{V}\oslash\ \mathbf{h}$ given posterior samples of $\mathbf{w}$, $\kappa$, $\eta^\star$, and $\mu^\star$.

```{r message=FALSE, warning=FALSE}
kappa       <- as.matrix(as_draws_df(fit_NIG$draws("kappa")))[,1]
etas        <- as.matrix(as_draws_df(fit_NIG$draws("etas")))[,1]
mus         <- as.matrix(as_draws_df(fit_NIG$draws("mus")))[,1]

V_post <- Vposterior(W_NIG, kappa, G, etas, mus, h)
```

In the following widget we can visualize the posterior mean of $\mathbf{V}\oslash\mathbf{h}$. 

```{r echo=FALSE}
plot.data.V <- data.frame(lon = mesh$loc[,1], lat = mesh$loc[,2]) 
plot.data.V$Vmean  <- colMeans(V_post)     

pal.V    <- colorNumeric(palette = "YlOrRd", domain = plot.data.V$Vmean)
leaflet(plot.data.V) %>%
  
  addTiles(group = "OpenStreetMap") %>%
  addProviderTiles(providers$Esri.WorldImagery, group = "Sattelite") %>% 
  
  addPolygons(data=mesh_map_proj, weight = 1, fill = FALSE, color = "#0A0708") %>%

  addCircleMarkers(lng = ~lon, lat = ~lat, color="black", 
                   stroke= TRUE, fill = TRUE, fillColor = ~pal.V(Vmean), 
                   radius = 5, fillOpacity = TRUE, weight = 1) %>%
  addLegend_decreasing(pal = pal.V, values = ~Vmean, opacity = 0.8, title = "",
                       position = "bottomright", decreasing = TRUE) %>%
  addLayersControl(baseGroups = c("OpenStreetMap", "Sattelite"),
                   options = layersControlOptions(collapsed = FALSE)) %>%
  addFullscreenControl()
```


The previous widget is interesting from an spatial statistics and exploratory analysis point of view. Maybe there are covariates that can explain the large peaks in the latent field. Therefore this widget can aid in improving the Gaussian model, since we can identify which nodes in the mesh require more flexibility, which may help in finding important covariates that we may be missing. For instance, near the city Cranbrook in the northeast region there is a red node which corresponds to a "hotpot". By looking at the satellite map and zooming in at this location we can see that this measurement was taken at an airport, and the dark asphalt can be creating an urban heat island effect. Other measurements were taken at airports. The coldspot in the northeast corner near the city  has higher altitude.  We can also see a drier area in the middle of the map which in part corresponds to the Oregon Rain Shadow region. An illustration of this effect is shown in following figure.

```{r rainshadow, out.width = '100%', fig.cap="Rain shadow effect. Infograph by Eileen Chontos. Taken from https://www.montananaturalist.org/blog-post/montanas-rain-shadow-explained/"}
knitr::include_graphics("../files/images/rainshadow.jpg")
```


## Refitting with covariates

Given the previous observations, we will refit the model with the following covariates:

- Altitude
- Distance to coastline (negative if location is in the ocean, positive on inland)
- Direct solar irradiance (power per unit area received from the sun annually)
- Pressure
- is.airport (1 if location was measured at an airport and 0 otherwise)
- is.ocean  (1 if location was measured at the ocean and 0 otherwise)

We removed 3 observations located in the ocean, where we could not find all the covariates. We define the design matrix `B` containing the covariates and the new projector matrix `A` next.

```{r message=FALSE, warning=FALSE}
weatherdata2 <- as.data.frame(read_csv("../files/data/weatherdata2.csv", col_names = TRUE))
Ny <- nrow(weatherdata2)

#Design Matrix
B = scale(weatherdata2[,c(3,5,7,8)])
B = cbind(B, is.ocean = weatherdata2$is.ocean) 
B = cbind(B, is.airport = weatherdata2$is.airport) 

#New projector matrix
A <- inla.spde.make.A(mesh = mesh, loc = as.matrix(weatherdata2[,c("lon","lat")]))
```

In the model block we only have to change the observation layer and the add the priors for the intercept and regression coefficients.  The complete Stan models can be found in  `..files\stan\GaussMaternSPDE.stan` and `..files\stan\NIGMaternSPDE.stan`.

```{}
//observation layer---------------------------
y ~ normal(m + B*beta + sigma*A*W, sigmae);

...

//prior layer---------------------------------
//prior for intercept
m ~ normal(0, 5); 
//prior for beta
beta ~ normal(0, 1); 
...
```

The data list sent to Stan is similar to before, but now we add `n_cov` which is the number of covariates and the design matrix `B`.

```{r eval=FALSE}
dat2 <- list(N        = N,
             Ny       = Ny,
             y        = weatherdata2$temp,
             h        = h,
             G        = as.matrix(G),
             A        = as.matrix(A),
             n_cov    = 6,
             B        = B,
             inter_points = inter_points,
             kappa_log    = kappa_log,
             det_log      = det_log,
             lambda1  = lambda1,
             lambda2  = lambda2,
             alphaeta = 0.5,
             thetamus  = 5)
```



### Gaussian fit

```{r eval=FALSE}
model_stan_Gauss2 <- cmdstan_model('../files/stan/GaussMaternSPDE2.stan')
fit_Gauss2 <- model_stan_Gauss2$sample(data = dat2, 
                                       chains = 2, 
                                       iter_warmup   = 200, 
                                       iter_sampling = 1000)

fit_Gauss2$save_object("../files/fits/fit_temp_Gauss2.rds")
```

Let us look at the summary. The posterior distributions of $\sigma_\epsilon$, $\sigma$ and $\kappa$ remained practically the same.

```{r}
fit_Gauss2 <- readRDS("../files/fits/fit_temp_Gauss2.rds")
knitr::kable(head(fit_Gauss2$summary(),9), "simple", row.names = NA, digits=2)
```

### NIG fit
```{r eval=FALSE}
model_stan_NIG2 <- cmdstan_model('../files/stan/NIGMaternSPDE2.stan')
fit_NIG2  <- model_stan_NIG2$sample(data = dat2, 
                                    chains = 2, 
                                    iter_warmup   = 200, 
                                    iter_sampling = 1000)

fit_NIG2$save_object("../files/fits/fit_temp_NIG2.rds")
```

We note that the posterior mean of $\eta^\star$ decreased, likely because the covariates can capture part of the peaks and short term variations in the data.

```{r}
fit_NIG2 <- readRDS("../files/fits/fit_temp_NIG2.rds")
knitr::kable(head(fit_NIG2$summary(),9), "simple", row.names = NA, digits=2)
```

### Comparizon

We plot next the posterior distribution of regression coefficient, where inner intervals include the 50\% quantiles and the outer intervals the 90\% quantiles. The posterior distributions are similar in the Gaussian and NIG models, although the `is.ocean` coefficient seems less ambiguous in the NIG model.  The posterior of the `is.airport` coefficient has mass mostly on the positive domain, however the 90\% credible interval includes the value 0. For a more definite conclusion about the heat island effect caused by the airports we would need more observations and observations that are more uniformly spread across the region. Regarding the other covariates, the direct solar irradiance, pressure and altitude had a positive effect and distance to the ocean and `is.ocean` had a negative effect on the temperature. 


```{r message=FALSE, warning=FALSE}
labs <- c("Altitude", "Is.ocean","Distance to ocean", "Pressure", "Direct solar irradiance","Is.airport")

mcmc_intervals(fit_Gauss2$draws(), pars = c("beta[1]","beta[2]","beta[3]","beta[4]","beta[5]","beta[6]"))+
  scale_y_discrete(labels = labs)

mcmc_intervals(fit_NIG2$draws(), pars = c("beta[1]","beta[2]","beta[3]","beta[4]","beta[5]","beta[6]"))+
  scale_y_discrete(labels = labs)
```


We again compare both models using the leave-one-out cross-validation estimates, which still gives preference to the NIG model, indicating a higher predictive performance. However, if we were only interested in accessing the relationships between the covariates and the temperature, then the conclusions we would arrive by using the latent Gaussian model would be practically the same as in the latent non-Gaussian model. 

```{r message=FALSE, warning=FALSE}
fit_Gauss2$loo()[[1]]
fit_NIG2$loo()[[1]]
```

### Posterior mean of $\mathbf{V}\oslash\mathbf{h}$

The posterior mean of $V_i/h_i$ decreased for several nodes in the mesh after adding the covariates, but still there are many nodes where $V_i/h_i$ is large.

```{r message=FALSE, warning=FALSE}
W_NIG       <- as.matrix(as_draws_df(fit_NIG2$draws("W"))[,1:N])
sigma_NIG   <- as.matrix(as_draws_df(fit_NIG2$draws("sigma")))[,1]
kappa       <- as.matrix(as_draws_df(fit_NIG2$draws("kappa")))[,1]
etas        <- as.matrix(as_draws_df(fit_NIG2$draws("etas")))[,1]
mus         <- as.matrix(as_draws_df(fit_NIG2$draws("mus")))[,1]

V_post <- Vposterior(W_NIG, kappa, G, etas, mus, h)
```

```{r echo=FALSE}
plot.data.V <- data.frame(lon = mesh$loc[,1], lat = mesh$loc[,2]) 
plot.data.V$Vmean  <- colMeans(V_post)     

pal.V    <- colorNumeric(palette = "YlOrRd", domain = plot.data.V$Vmean)
leaflet(plot.data.V) %>%
  
  addTiles(group = "OpenStreetMap") %>%
  addProviderTiles(providers$Esri.WorldImagery, group = "Sattelite") %>% 
  
  addPolygons(data=mesh_map_proj, weight = 1, fill = FALSE, color = "#0A0708") %>%

  addCircleMarkers(lng = ~lon, lat = ~lat, color="black", 
                   stroke= TRUE, fill = TRUE, fillColor = ~pal.V(Vmean), 
                   radius = 5, fillOpacity = TRUE, weight = 1) %>%
  addLegend_decreasing(pal = pal.V, values = ~Vmean, opacity = 0.8, title = "",
                       position = "bottomright", decreasing = TRUE) %>%
  addLayersControl(baseGroups = c("OpenStreetMap", "Sattelite"),
                   options = layersControlOptions(collapsed = FALSE)) %>%
  addFullscreenControl()
```



<!--

### Things to do

Reduce alpha to 10%...
make priors for beta and m larger
improve interpolation new algorithm search thing is slow...

Add likelihood of large event? risk or something??? Maybe good to add on plot. P(region larger than 4) for Gaussian and NIG

by making sigma prior take higher values you are making latent field more important and you get more non-Gaussian effects

prior for sigmae makes a difference - shrink it to 0, the more impoirtant latent field (hiher sigma/sigmae) the higher will be etas
the observational noise can capture already some of the short term variations... Also prior for sigmae shrunk to 1 seems to make algorithm faster?

posterior of etas and V quite sensible on the priors for sigmae and sigma
example" pressure data if sigmae>sigma then latent field less relevant and jumos carptured by observastional noise -> etas small
example" pressure data if sigma>sigmae then latent field more relevant and etas increases


Run more iterations to decrease loo standard deviations, always 4 chains...

try reparameterizing sigma and kappa in Gausian case and check for improvements... none

convert to marginal standard deviation and practical correlation range which make more sense none

choose lower alpha_etas like 10% or even less
